{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "EbH-0BeQqhiR",
        "Tz_j0aU0z-xl",
        "OBv2dvxvqwOK",
        "GyNxkzXIta1x",
        "za3PcPlZ05Aq",
        "sWevghni4MEw"
      ],
      "authorship_tag": "ABX9TyMB6s15tpX0Z2+8Ca29O+kX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harvard-visionlab/neuro_science_fiction/blob/main/2022/mitchell_feature_modeling_class_dropFeatures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NeuroScienceFiction Mind Reading Data Analysis"
      ],
      "metadata": {
        "id": "EbH-0BeQqhiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -R NeuroSciFi-Workshop\n",
        "!rm -R brain_data"
      ],
      "metadata": {
        "id": "D_rrRpgqOqWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# setup (run this section first)"
      ],
      "metadata": {
        "id": "Tz_j0aU0z-xl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## download data & precomputed results"
      ],
      "metadata": {
        "id": "OBv2dvxvqwOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget -c https://www.dropbox.com/s/74s566ppu1nbo74/brain_data.tar.gz\n",
        "!tar -xvf brain_data.tar.gz\n",
        "!rm brain_data.tar.gz"
      ],
      "metadata": {
        "id": "EKKiDSsdqywB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!mkdir -p /content/NeuroSciFi-Workshop/\n",
        "!rm -R /content/NeuroSciFi-Workshop/\n",
        "!wget -c https://www.dropbox.com/s/pox900f93y6pkin/FeatureRatings.tar.gz\n",
        "!mkdir -p /content/NeuroSciFi-Workshop/\n",
        "!tar -xvf FeatureRatings.tar.gz\n",
        "!mv FeatureRatings ./NeuroSciFi-Workshop/FeatureRatings\n",
        "!rm -R FeatureRatings.tar.gz"
      ],
      "metadata": {
        "id": "E9Ifia8cx6QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget -c https://www.dropbox.com/s/r4xm9qruw4dqb0f/Results-BrainPrediction.tar.gz\n",
        "!tar -xvf Results-BrainPrediction.tar.gz\n",
        "!mv Results-BrainPrediction ./NeuroSciFi-Workshop/Results-BrainPrediction\n",
        "!rm -R Results-BrainPrediction.tar.gz"
      ],
      "metadata": {
        "id": "EPZzHt2H81fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget -c https://www.dropbox.com/s/tyoagsr0g8nlurr/Results-ByFeature.tar.gz\n",
        "!tar -xvf Results-ByFeature.tar.gz\n",
        "!mkdir -p ./NeuroSciFi-Workshop/Results-ByFeature \n",
        "!rm -R ./NeuroSciFi-Workshop/Results-ByFeature\n",
        "!mv Results-ByFeature ./NeuroSciFi-Workshop/Results-ByFeature\n",
        "!rm -R Results-ByFeature.tar.gz"
      ],
      "metadata": {
        "id": "rZdxTAOiIamT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## analysis code"
      ],
      "metadata": {
        "id": "also2Di0q0-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "metadata": {
        "id": "7K55qM0Hq11w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "drive = '/content/NeuroSciFi-Workshop'\n",
        "if not os.path.exists(drive):\n",
        "  os.makedirs(drive)\n"
      ],
      "metadata": {
        "id": "4m1p_EZAvF0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### handle feature data"
      ],
      "metadata": {
        "id": "GyNxkzXIta1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd \n",
        "from datetime import date\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from collections import defaultdict\n",
        "import seaborn as sns \n",
        "from pdb import set_trace \n",
        "\n",
        "def download_ratings(team_name, dropRaters=[], dropFeatures=[]):\n",
        "  print(f\"==> Downloading data: {team_name}\")\n",
        "  team_name = team_name.lower()\n",
        "  folder = os.path.join(drive, 'FeatureRatings')\n",
        "  if not os.path.exists(folder):\n",
        "    os.makedirs(folder)\n",
        "  filename = os.path.join(folder, f\"{team_name}_Ratings.csv\")\n",
        "  url = f\"https://scorsese.wjh.harvard.edu/turk/experiments/nsf/survey/{team_name}/data\"\n",
        "  df = pd.read_csv(url)\n",
        "  df = df[~df.workerId.isin(dropRaters)]\n",
        "  df = df[~df.featureName.isin(dropFeatures)]\n",
        "\n",
        "  # drop rows for raters with incomplete datasets\n",
        "  # assuming max_count of ratings is expected/desired count\n",
        "  counts = df.groupby('workerId').rating.count()\n",
        "  max_count = counts.max()\n",
        "  dropRaters = counts[counts<max_count].index.values\n",
        "  if len(dropRaters) > 0:\n",
        "    print(f\"==> Dropping incomplete datasets: {dropRaters}\")\n",
        "    df = df[~df.workerId.isin(dropRaters)]\n",
        "  \n",
        "  df.to_csv(filename, index=False)\n",
        "\n",
        "  return df \n",
        "\n",
        "def load_ratings(team_name, dropFeatures=[]):\n",
        "  team_name = team_name.lower()\n",
        "  filename = os.path.join(drive, 'FeatureRatings', f\"{team_name}_Ratings.csv\")    \n",
        "  df = pd.read_csv(filename)\n",
        "  group_name = df.iloc[0].groupName\n",
        "  num_items = len(df.itemName.unique())\n",
        "  num_features = len(df.featureName.unique())\n",
        "  num_raters = len(df.workerId.unique())\n",
        "\n",
        "  print(\"=\"*50)\n",
        "  print(f\"FEATURE RATINGS: {group_name}\")\n",
        "  print(f\"{num_items} items, {num_features} features, {num_raters} raters\")\n",
        "  print(date.today().strftime(\"%B %d, %Y\"))\n",
        "  print(\"=\"*50)\n",
        "\n",
        "  items = sorted(df.itemName.unique())\n",
        "  features = sorted(df.featureName.unique())\n",
        "  raters = sorted(df.workerId.unique())\n",
        "  num_rows = len(df)\n",
        "  print(\"items:\", items)\n",
        "  print(\"features:\", features)\n",
        "  print(\"raters:\", raters)\n",
        "  expected_rows = len(items) * len(features) * len(raters)\n",
        "  assert expected_rows == len(df), f\"Oops, expected {expected_rows}, got {len(df)}\"\n",
        "  print(\"number of rows:\", num_rows)\n",
        "\n",
        "  return df\n",
        "\n",
        "def get_feature_data(team_name, dropFeatures=[]):\n",
        "\n",
        "  df = load_ratings(team_name, dropFeatures=dropFeatures)\n",
        "\n",
        "  itemNames = sorted(df.itemName.unique())\n",
        "  featureNames = sorted(df.featureName.unique())\n",
        "  raters = sorted(df.workerId.unique())\n",
        "  numItems = len(itemNames)\n",
        "  numFeatures = len(featureNames)\n",
        "  numRaters = len(raters)\n",
        "\n",
        "  R = np.zeros((numItems,numFeatures))\n",
        "\n",
        "  # itemNames in same order as brain data (groupbed by category)\n",
        "  itemNames = ['bear', 'cat', 'cow', 'dog', 'horse', 'arm', 'eye', 'foot', 'hand',\n",
        "              'leg', 'apartment', 'barn', 'church', 'house', 'igloo', 'arch',\n",
        "              'chimney', 'closet', 'door', 'window', 'coat', 'dress', 'pants',\n",
        "              'shirt', 'skirt', 'bed', 'chair', 'desk', 'dresser', 'table',\n",
        "              'ant', 'bee', 'beetle', 'butterfly', 'fly', 'bottle', 'cup',\n",
        "              'glass', 'knife', 'spoon', 'bell', 'key', 'refrigerator',\n",
        "              'telephone', 'watch', 'chisel', 'hammer', 'pliers', 'saw',\n",
        "              'screwdriver', 'carrot', 'celery', 'corn', 'lettuce', 'tomato',\n",
        "              'airplane', 'bicycle', 'car', 'train', 'truck']\n",
        "\n",
        "  for itemNum,itemName in enumerate(itemNames):\n",
        "    for featureNum,featureName in enumerate(featureNames):\n",
        "      subset = df[(df.itemName==itemName) & (df.featureName==featureName)]\n",
        "      numRatings = len(subset)\n",
        "      assert numRatings==numRaters, f\"Oops, expected {numRaters} ratings, got {numRatings}\"\n",
        "      R[itemNum,featureNum] = subset.ratingScaled.mean()\n",
        "\n",
        "  feature_data = dict(\n",
        "      R=R,\n",
        "      itemNames=np.asarray(itemNames, dtype='object'),\n",
        "      featureNames=np.asarray(featureNames, dtype='object')\n",
        "  )\n",
        "\n",
        "  return feature_data"
      ],
      "metadata": {
        "id": "B-D3dk_DvBtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### brain-prediction and mind-reading"
      ],
      "metadata": {
        "id": "za3PcPlZ05Aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastprogress import master_bar, progress_bar \n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "import numpy as np \n",
        "import scipy.io as sio\n",
        "from scipy.stats import zscore\n",
        "from types import SimpleNamespace \n",
        "from collections import defaultdict \n",
        "from scipy import stats \n",
        "from pdb import set_trace \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge, RidgeCV, LinearRegression\n",
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "1nEQyiiA1mY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pearson_dist(a,b):\n",
        "  return 1 - stats.pearsonr(a,b)[0]\n",
        "\n",
        "dissimilarity_functions = dict(\n",
        "    pearson_dist=pearson_dist,\n",
        ")\n",
        "\n",
        "def compare_actual_predicted(a,p,dissimilarity_fun,accuracy_measure='combo'):\n",
        "  dist11=dissimilarity_fun(p[0,:],a[0,:])\n",
        "  dist22=dissimilarity_fun(p[1,:],a[1,:])\n",
        "  dist12=dissimilarity_fun(p[0,:],a[1,:])\n",
        "  dist21=dissimilarity_fun(p[1,:],a[0,:])\n",
        "\n",
        "  if accuracy_measure == 'combo':\n",
        "    # sum the dissimilarity scores for the 2 right and 2 wrong comparisons\n",
        "    totalDistCorrectCombo = dist11+dist22;\n",
        "    totalDistWrongCombo = dist12+dist21;\n",
        "    \n",
        "    # got it right if the dissimilarity score for the \"right combo\" is lower\n",
        "    correct=float(totalDistCorrectCombo<totalDistWrongCombo)\n",
        "    \n",
        "  else:\n",
        "    correct=(float(dist11<dist12) + float(dist22<dist21))/2 # percent correct, individual predictions\n",
        "\n",
        "  return dict(\n",
        "      dist11=dist11,\n",
        "      dist22=dist22,\n",
        "      dist12=dist12,\n",
        "      dist21=dist21,\n",
        "      correct=correct\n",
        "  )"
      ],
      "metadata": {
        "id": "uqgHxDQx18Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def botastic_predict_features(prototype_features, prototype_scores, test_scores):\n",
        "  '''\n",
        "    Predict test_features based on similarity between test_scores\n",
        "    and prototype_scores, given the prototype_features. Essentially, \n",
        "    the test_features are estimated to be a combination of the\n",
        "    protype_features weighted by similarity between test_item and \n",
        "    each prototype.\n",
        "\n",
        "    Based on bo's eye-movement code, where the protype_features are screen\n",
        "    coordinates, the prototype_scores are eye-tracker calibration measurements,\n",
        "    and the test scores are the current eye-position measurements. By measuring\n",
        "    the similarity between test_scores and prototype_scores, you can\n",
        "    infer the test_features (current eye-position in screen coordinates).\n",
        "\n",
        "    But this can be generalized to our mind-reading task, where the \n",
        "    protype_features are features of objects, the prototype_scores are\n",
        "    the neural resposnes to those objects, and the test_scores are \n",
        "    the neural responses to test objects. By measuring the similarity\n",
        "    between test_brain_responses and prototype_brain_responses, you can\n",
        "    infer the test_item_features.\n",
        "\n",
        "    We can even flip this, and treat the neural responses as \"features\",\n",
        "    and use similarity in feature-space\n",
        "\n",
        "  '''\n",
        "  num_proto = prototype_scores.shape[0]\n",
        "\n",
        "  scores = np.concatenate([prototype_scores, test_scores])\n",
        "\n",
        "  # pairwise distance between all scores\n",
        "  dists = squareform(pdist(scores, metric='euclidean'))\n",
        "\n",
        "  # all scores vs. prototypes only (a)\n",
        "  d = dists[:,0:num_proto]\n",
        "\n",
        "  # use least squares to extrapolate from the prototypes\n",
        "  # x is the matrix that solves prototype_features = d_prototype @ x\n",
        "  # e.g., feature[0,0] = sum( d[0] * x[:,0])\n",
        "  # Item0's Feature0 is the similarity of Item0 to each prototype (d[0]), times some weight (x[:,0])\n",
        "  # Item1's Feature0 is the similarity of Item1 to each prototype (d[1]), times those same weights (x[:,0])\n",
        "  # ... etc\n",
        "  # Here we use lstsq to find weights the work across all protypes, then apply to test items too\n",
        "  x,resid,rank,s = np.linalg.lstsq(d[0:num_proto,:], prototype_features, rcond=None)\n",
        "\n",
        "  # matrix multiple the full distance matrix (d) times the least squares solution\n",
        "  tmp = (d @ x)\n",
        "\n",
        "  # should recover the protype features\n",
        "  extrap_prototype_features = tmp[0:num_proto,:]\n",
        "\n",
        "  # finally the extrapolated test item features\n",
        "  predicted_features = tmp[num_proto:,:]\n",
        "\n",
        "  return predicted_features\n",
        "  "
      ],
      "metadata": {
        "id": "yS7s0anb11n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_brain_data(brain_data, num_voxels=None, zscore=False):\n",
        "  D = brain_data['D']\n",
        "  D = D.mean(axis=2) # average across repetitions/runs \n",
        "  if zscore:  \n",
        "    D = zscore(D, axis=0, ddof=1) # z-score across items\n",
        "  N = min(num_voxels,D.shape[1]) if num_voxels is not None else D.shape[1]\n",
        "\n",
        "  # sortIdx comes from MATLAB, and is 1-indexed, so subtract 1\n",
        "  sortIdx = brain_data['sortIdx'][0:N] - 1\n",
        "  D = D[:,sortIdx] # % take the N most reliable voxels (consistent patterns across runs)\n",
        "\n",
        "  return D \n",
        "\n",
        "def prepare_ratings(feature_data, shuffle=False):\n",
        "  if feature_data['R'].shape[1]==60:\n",
        "    R = np.transpose(feature_data['R'])\n",
        "  else:\n",
        "    R = feature_data['R']  \n",
        "\n",
        "  if shuffle:\n",
        "    R = np.array([r[np.random.permutation(r.shape[0])] for r in R])\n",
        "  \n",
        "  return R\n"
      ],
      "metadata": {
        "id": "7GgJM8DA07A8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_feature_model(numItems, item1, item2, D, R):\n",
        "  # get train and test items\n",
        "  all_items = np.array(range(numItems))\n",
        "  test_items = ((all_items==item1) | (all_items==item2))\n",
        "  train_items = test_items==False \n",
        "\n",
        "  # get the training item brain response and features\n",
        "  trainBrainData=D[train_items,:]\n",
        "  trainItemFeatures=R[train_items,:]\n",
        "  scalerX = StandardScaler()\n",
        "  scalerY = StandardScaler()\n",
        "  trainX = scalerX.fit_transform(trainItemFeatures)\n",
        "  trainY = scalerY.fit_transform(trainBrainData)\n",
        "\n",
        "  # get the test item brain response and features \n",
        "  testBrainData=D[test_items,:]\n",
        "  testItemFeatures=R[test_items,:]\n",
        "  testX = scalerX.transform(testItemFeatures)\n",
        "  testY = scalerY.transform(testBrainData)\n",
        "  \n",
        "  # learn feature->voxel mapping from training data \n",
        "  reg = LinearRegression(fit_intercept=False).fit(trainX, trainY)\n",
        "  score = reg.score(trainX, trainY)  \n",
        "\n",
        "  return reg, score, trainX, trainY, testX, testY"
      ],
      "metadata": {
        "id": "a8wsQZ-x1RHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doBrainPredictionEncodingModel(reg, testX, testY, dissimilarity_fun, append_results):\n",
        "  predBrainData = reg.predict(testX)\n",
        "  predBrain2 = (testX @ np.transpose(reg.coef_)) + reg.intercept_\n",
        "  assert np.allclose(predBrain2, predBrainData), \"oops, no matchy\"    \n",
        "\n",
        "  task = 'brain_prediction'\n",
        "  method = 'encoding_model'\n",
        "  for scoring_method in ['individual', 'combo']:\n",
        "    res = compare_actual_predicted(testY, \n",
        "                                   predBrainData,\n",
        "                                   dissimilarity_fun,\n",
        "                                   accuracy_measure=scoring_method)\n",
        "    append_results(res, task, method, scoring_method)\n",
        "\n",
        "def doMindReadingEncodingModel(reg, testX, testY, dissimilarity_fun, append_results):\n",
        "  predFeatures = (testY @ reg.coef_)\n",
        "  task = 'mind_reading'\n",
        "  method = 'encoding_model'\n",
        "  for scoring_method in ['individual', 'combo']:\n",
        "    res = compare_actual_predicted(testX,\n",
        "                                   predFeatures,\n",
        "                                   dissimilarity_fun,\n",
        "                                   accuracy_measure=scoring_method)\n",
        "    append_results(res, task, method, scoring_method)"
      ],
      "metadata": {
        "id": "t0E3u0_z1TdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doBrainPredictionBotasticTemplates(trainX, trainY, testX, testY, \n",
        "                                       dissimilarity_fun, append_results):\n",
        "  '''\n",
        "    trainX: features of training items\n",
        "    trainY: neural responses to training items \n",
        "    testX: features of test items\n",
        "    testY: neural responses to test items\n",
        "  '''\n",
        "  predBrainData = botastic_predict_features(trainY, trainX, testX)\n",
        "  task = 'brain_prediction'\n",
        "  method = 'botastic_templates'\n",
        "  for scoring_method in ['individual', 'combo']:\n",
        "    res = compare_actual_predicted(testY,\n",
        "                                   predBrainData,\n",
        "                                   dissimilarity_fun,\n",
        "                                   accuracy_measure=scoring_method)\n",
        "    append_results(res, task, method, scoring_method)\n",
        "\n",
        "def doMindReadingBotasticTemplates(trainX, trainY, testX, testY, \n",
        "                                   dissimilarity_fun, append_results):\n",
        "  '''\n",
        "    trainX: features of training items\n",
        "    trainY: neural responses to training items \n",
        "    testX: features of test items\n",
        "    testY: neural responses to test items\n",
        "  '''\n",
        "  predFeatures = botastic_predict_features(trainX, trainY, testY)\n",
        "  task = 'mind_reading'\n",
        "  method = 'botastic_templates'\n",
        "  for scoring_method in ['individual', 'combo']:\n",
        "    res = compare_actual_predicted(testX,\n",
        "                                   predFeatures,\n",
        "                                   dissimilarity_fun,\n",
        "                                   accuracy_measure=scoring_method)\n",
        "    append_results(res, task, method, scoring_method)    "
      ],
      "metadata": {
        "id": "AXkT-SMB1Wp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doBrainAndFeaturePrediction(brain_data, feature_data, dissimilarity_fun,\n",
        "                                prefs, shuffle_features=False, testIndividualFeatures=False, \n",
        "                                mb=None):\n",
        "  '''Hold-two-out prediction of brain_data from feature_data (and vice-versa)\n",
        "\n",
        "    featureData: [numItems,numFeatures] array representing the features of each item\n",
        "    brainData: [numItems,numVoxels] array representing how much each voxel responds to each item\n",
        "\n",
        "    For all possible pairs of items (60 items = 1770 pairs!), we hold out \n",
        "    the test pair, and use the remaining 58 items to learn the mapping\n",
        "    between features and voxel responses (i.e., determine the beta weight\n",
        "    for each feature and each voxel).\n",
        "\n",
        "    We then use the learned mapping to predict responses for the two items.\n",
        "    For each of those items, we multiply their feature values times the\n",
        "    beta values for each voxel to determine how much each voxel will respond\n",
        "    to each item. We then compare the predicted patterns to the actual patterns.\n",
        "    \n",
        "  '''\n",
        "\n",
        "  # make sure items are in the same order for brain data and feature data,\n",
        "  # otherwise this is a lost cause:\n",
        "  assert all(brain_data['itemName'] == feature_data['itemNames']), \"oops, names don't match!\"\n",
        "\n",
        "  # get some metadata from datasets\n",
        "  categoryNum = brain_data['categoryNum']\n",
        "  categoryName = brain_data['categoryName']\n",
        "  itemName = brain_data['itemName']\n",
        "  brain_sub = brain_data['brain_sub']\n",
        "  featureNames = feature_data['featureNames']\n",
        "  print(\"ANALYZING SUBJECT NUMBER:\", brain_sub)\n",
        "\n",
        "  # prepare brain activations (numConditions x numVoxels x numRepetitions)\n",
        "  D = prepare_brain_data(brain_data, num_voxels=prefs.num_voxels, zscore=prefs.zscore_braindata)\n",
        "\n",
        "  # prepare feature ratings\n",
        "  R = prepare_ratings(feature_data, shuffle=shuffle_features)\n",
        "\n",
        "  # get dissimilarity function\n",
        "  dissimilarity_fun = dissimilarity_functions[prefs.sim_metric]\n",
        "\n",
        "  # prepare results\n",
        "  results = defaultdict(list) # track results \n",
        "  results_by_feature = defaultdict(list) # track how well each feature predicts\n",
        "  all_betas=[]; # so we can visualize the \"weights\"\n",
        "\n",
        "  # for all possible pairs of items\n",
        "  numItems = D.shape[0]\n",
        "  pb = progress_bar(range(1770), parent=mb) # 60 choose 2\n",
        "  c = 0\n",
        "  for item1 in range(0,numItems-1):\n",
        "    for item2 in range(item1+1,numItems):\n",
        "      if (item1==item2): continue\n",
        "      pb.update(c)\n",
        "      c += 1\n",
        "      \n",
        "      # fit the encoding model\n",
        "      reg,score,trainX,trainY,testX,testY = fit_feature_model(numItems, item1, item2, D, R)\n",
        "\n",
        "      # store the betas\n",
        "      all_betas.append(reg.coef_)\n",
        "\n",
        "      # wrapper to add rows to the results for different analysis methods\n",
        "      def append_results(res, task, method, scoring_method):\n",
        "        same_category = int(categoryNum[item1]==categoryNum[item2])\n",
        "\n",
        "        results['team_name'].append(prefs.teamName)\n",
        "        results['brain_subject'].append(brain_sub)\n",
        "        results['item1_idx'].append(item1)\n",
        "        results['item2_idx'].append(item2)\n",
        "        results['item1_name'].append(itemName[item1])\n",
        "        results['item2_name'].append(itemName[item2])\n",
        "        results['item1_cat'].append(categoryName[item1])\n",
        "        results['item2_cat'].append(categoryName[item2])\n",
        "        results['itemPair'].append((item1,item2))\n",
        "        results['same_category'].append(same_category)\n",
        "        results['r2_score'].append(score.mean())\n",
        "\n",
        "        results['task'].append(task)\n",
        "        results['method'].append(method)\n",
        "        results['scoring'].append(scoring_method)\n",
        "        results['dist11'].append(res['dist11'])\n",
        "        results['dist22'].append(res['dist22'])\n",
        "        results['dist12'].append(res['dist12'])\n",
        "        results['dist21'].append(res['dist21'])\n",
        "        results['correct'].append(res['correct'])\n",
        "\n",
        "      # ================================================\n",
        "      #  Brain Prediction / Mind Reading\n",
        "      # ================================================\n",
        "\n",
        "      # predict brain response from features using feature-voxel encoding model\n",
        "      doBrainPredictionEncodingModel(reg, testX, testY, dissimilarity_fun, append_results)\n",
        "\n",
        "      # predict features (items) from brain response using feature-voxel encoding model\n",
        "      doMindReadingEncodingModel(reg, testX, testY, dissimilarity_fun, append_results)\n",
        "      \n",
        "      # predict brain response using feature-similarity-weighted-neural-templates\n",
        "      doBrainPredictionBotasticTemplates(trainX, trainY, testX, testY, dissimilarity_fun, append_results)\n",
        "\n",
        "      # predict features (items) from neural-similarity-weighted-feature-templates\n",
        "      doMindReadingBotasticTemplates(trainX, trainY, testX, testY, dissimilarity_fun, append_results)\n",
        "\n",
        "      # ================================================\n",
        "      #  analyze each feature independently\n",
        "      # ================================================\n",
        "      if testIndividualFeatures==True:\n",
        "        for feat_num, feat_name in enumerate(progress_bar(featureNames, parent=mb)):\n",
        "          reg = LinearRegression().fit(trainX[:,[feat_num]], trainY)\n",
        "          r2_score = reg.score(trainX[:,[feat_num]], trainY)\n",
        "\n",
        "          def append_results(res, task, method, scoring_method):\n",
        "            same_category = int(categoryNum[item1]==categoryNum[item2])\n",
        "\n",
        "            results_by_feature['team_name'].append(prefs.teamName)\n",
        "            results_by_feature['feat_num'].append(feat_num)\n",
        "            results_by_feature['feat_name'].append(feat_name)\n",
        "            results_by_feature['brain_subject'].append(brain_sub)\n",
        "            results_by_feature['item1_idx'].append(item1)\n",
        "            results_by_feature['item2_idx'].append(item2)\n",
        "            results_by_feature['item1_name'].append(itemName[item1])\n",
        "            results_by_feature['item2_name'].append(itemName[item2])\n",
        "            results_by_feature['item1_cat'].append(categoryName[item1])\n",
        "            results_by_feature['item2_cat'].append(categoryName[item2])\n",
        "            results_by_feature['itemPair'].append((item1,item2))\n",
        "            results_by_feature['same_category'].append(same_category)\n",
        "            results_by_feature['r2_score'].append(r2_score.mean())\n",
        "\n",
        "            results_by_feature['task'].append(task)\n",
        "            results_by_feature['method'].append(method)\n",
        "            results_by_feature['scoring'].append(scoring_method)\n",
        "            results_by_feature['dist11'].append(res['dist11'])\n",
        "            results_by_feature['dist22'].append(res['dist22'])\n",
        "            results_by_feature['dist12'].append(res['dist12'])\n",
        "            results_by_feature['dist21'].append(res['dist21'])\n",
        "            results_by_feature['correct'].append(res['correct'])\n",
        "                    \n",
        "          doBrainPredictionEncodingModel(reg, testX[:,[feat_num]], testY, dissimilarity_fun, append_results)\n",
        "            \n",
        "  return results, results_by_feature, all_betas"
      ],
      "metadata": {
        "id": "BzoytkMu1ZCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from types import SimpleNamespace\n",
        "\n",
        "def loadmat(filename):\n",
        "  D = sio.loadmat(filename, \n",
        "                  squeeze_me=True,\n",
        "                  struct_as_record=True, \n",
        "                  simplify_cells=True)\n",
        "  return D\n",
        "  \n",
        "def run_full_analysis(teamName, \n",
        "                      sub_list=[1,2,3,4,5,6,7,8,9], \n",
        "                      num_voxels=500, \n",
        "                      sim_metric='pearson_dist', \n",
        "                      zscore_braindata=False, \n",
        "                      testIndividualFeatures=True,\n",
        "                      num_shuffles=100):\n",
        "  '''Run the brain-prediction and mind-reading analyses, using both\n",
        "  standard feature modeling and the botastic protype method. Include\n",
        "  a shuffle test for good measure.'''\n",
        "  prefs = SimpleNamespace(\n",
        "      teamName = teamName,\n",
        "      num_voxels = num_voxels,\n",
        "      sim_metric=sim_metric, \n",
        "      zscore_braindata=zscore_braindata,\n",
        "      num_shuffles=num_shuffles,\n",
        "  )\n",
        "  print(prefs)\n",
        "\n",
        "  # load feature_data for this team\n",
        "  # featureFileName = feature_sets[prefs.teamName]\n",
        "  featureFileName = os.path.join(drive, 'FeatureData', f'{teamName}_Features.mat')\n",
        "  feature_data = loadmat(featureFileName)\n",
        "  dissimilarity_fun = dissimilarity_functions[prefs.sim_metric]\n",
        "\n",
        "  # loop through brain subjects\n",
        "  df = None\n",
        "  feat_df = None\n",
        "  shuffle_df = None\n",
        "  mb = master_bar(sub_list)\n",
        "  betas_by_subject = []\n",
        "  brain_meta = []\n",
        "  for brain_sub in mb:\n",
        "    # load brain data for this subject\n",
        "    brain_data = loadmat(f'./brain_data/data-science-P{brain_sub}_converted.mat')\n",
        "    brain_data['brain_sub'] = brain_sub\n",
        "\n",
        "    # do full brain-prediction / mind-reading analysis\n",
        "    output = doBrainAndFeaturePrediction(brain_data, feature_data, dissimilarity_fun,\n",
        "                                         prefs, testIndividualFeatures=testIndividualFeatures, \n",
        "                                         shuffle_features=False, mb=mb)\n",
        "    \n",
        "    # format and store the results\n",
        "    results, results_by_feature, all_betas = output\n",
        "    betas = np.stack(all_betas).mean(axis=0)\n",
        "    betas_by_subject.append(betas)\n",
        "\n",
        "    df_ = pd.DataFrame(results)\n",
        "    df = pd.concat([df, df_])\n",
        "\n",
        "    feat_df_ = pd.DataFrame(results_by_feature)\n",
        "    feat_df = pd.concat([feat_df, feat_df_])\n",
        "\n",
        "    meta = brain_data['meta']\n",
        "    meta['sortIdx'] = brain_data['sortIdx']\n",
        "    meta['voxelReliability'] = brain_data['voxelReliability']\n",
        "    brain_meta.append(meta)\n",
        "\n",
        "    # do a shuffle test\n",
        "    # for shuffle_num in range(num_shuffles):\n",
        "    #   output = doBrainAndFeaturePrediction(brain_data, feature_data, dissimilarity_fun,\n",
        "    #                                        prefs, testIndividualFeatures=False, \n",
        "    #                                        shuffle_features=True, mb=mb)\n",
        "\n",
        "  return dict(\n",
        "      prefs=prefs, \n",
        "      df=df, \n",
        "      feat_df=feat_df, \n",
        "      betas=betas_by_subject,\n",
        "      brain_meta=brain_meta,\n",
        "      feature_data=feature_data\n",
        "  )\n",
        "\n",
        "def compute_prediction_summary(results, task, method, scoring):\n",
        "\n",
        "  summary = defaultdict(list)\n",
        "  sub_nums = sorted(results.brain_subject.unique())\n",
        "  \n",
        "  for sub_num in sub_nums:\n",
        "    subset = results[(results.brain_subject==sub_num) & (results.task==task) & \n",
        "                     (results.method==method) & (results.scoring==scoring)]\n",
        "    assert len(subset)==1770, f\"Oops, expected 1770 rows, got {len(subset)}\"\n",
        "    summary['accuracyOverall'].append(subset.correct.mean())\n",
        "    summary['accuracySameCat'].append(subset[subset.same_category==1].correct.mean())\n",
        "    summary['accuracyDiffCat'].append(subset[subset.same_category==0].correct.mean())\n",
        "    # summary['aveAccByFeature'].append()\n",
        "\n",
        "  summary['accuracyOverall'] = np.array(summary['accuracyOverall'])\n",
        "  summary['accuracySameCat'] = np.array(summary['accuracySameCat'])\n",
        "  summary['accuracyDiffCat'] = np.array(summary['accuracyDiffCat'])\n",
        "\n",
        "  summary['ave_accuracyOverall'] = summary['accuracyOverall'].mean()\n",
        "  summary['ave_accuracySameCat'] = summary['accuracySameCat'].mean()\n",
        "  summary['ave_accuracyDiffCat'] = summary['accuracyDiffCat'].mean()\n",
        "  \n",
        "  return summary\n",
        "\n",
        "def save_full_results(results, folder=os.path.join(drive, 'Results-BrainPrediction')):\n",
        "  \n",
        "  if not os.path.exists(folder):\n",
        "      os.makedirs(folder)\n",
        "\n",
        "  prefs = results['prefs']\n",
        "  df = results['df']\n",
        "  feat_df = results['feat_df']\n",
        "  betas = results['betas']\n",
        "  \n",
        "  if feat_df is not None:\n",
        "    filename = f'{prefs.teamName}_{prefs.num_voxels}_results_features.pth.tar'\n",
        "  else:\n",
        "    filename = f'{prefs.teamName}_{prefs.num_voxels}_results.pth.tar'\n",
        "  filename = os.path.join(folder, filename)\n",
        "\n",
        "  torch.save(results, filename)"
      ],
      "metadata": {
        "id": "yHfgwQFf1bx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### comparison and visualization"
      ],
      "metadata": {
        "id": "sWevghni4MEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob \n",
        "from scipy.stats import ttest_rel\n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "def compare_to_mitchell(teamName, \n",
        "                        num_voxels=500, \n",
        "                        task=\"brain_prediction\",\n",
        "                        method=\"encoding_model\",\n",
        "                        score=\"individual\",\n",
        "                        accuracy='accuracyOverall',\n",
        "                        title=\"\",\n",
        "                        ax=None, \n",
        "                        ylabel=\"percent correct\"):\n",
        "\n",
        "  sns.set(rc={\n",
        "      'figure.figsize':(7,8),\n",
        "      'axes.grid': False,\n",
        "  })\n",
        "  sns.set(font_scale = 1.5)\n",
        "  sns.set_style(\"white\")\n",
        "\n",
        "  files = glob(os.path.join(drive, f'./Results-BrainPrediction/*{teamName}*{num_voxels}*features*'))\n",
        "  assert len(files)==1, f\"Oops, expected 1 file, got {len(files)}\"\n",
        "  results1 = torch.load(files[0])\n",
        "  summary1 = compute_prediction_summary(results1['df'], task, method, score)\n",
        "  \n",
        "\n",
        "  files = glob(os.path.join(drive, f'./Results-BrainPrediction/*Mitchell*{num_voxels}*features*'))\n",
        "  assert len(files)==1, f\"Oops, expected 1 file, got {len(files)}\"\n",
        "  results2 = torch.load(files[0])\n",
        "  summary2 = compute_prediction_summary(results2['df'], task, method, score)\n",
        "\n",
        "  a = summary1[accuracy]\n",
        "  b = summary2[accuracy]\n",
        "  tval, pval = ttest_rel(a, b, axis=0, nan_policy='propagate', alternative='two-sided')\n",
        "  df = len(a)-1\n",
        "  # print(f\"t({df})={tval:4.2f}, p={pval:4.3f}\")\n",
        "  p = \"(n.s.)\" if pval >= .05 else f\"(p={pval:4.3f})\"\n",
        "\n",
        "  results = defaultdict(list)\n",
        "  for brainSubject,(d1,d2) in enumerate(zip(a,b)):\n",
        "    results['brainSubject'].append(brainSubject)\n",
        "    results['teamName'].append(teamName)\n",
        "    results['percent correct'].append(d1)\n",
        "    \n",
        "    results['brainSubject'].append(brainSubject)\n",
        "    results['teamName'].append('Mitchell')\n",
        "    results['percent correct'].append(d2)\n",
        "  results = pd.DataFrame(results)\n",
        "\n",
        "  mitchell = results[results.teamName==\"Mitchell\"]['percent correct'].mean()\n",
        "  other = results[results.teamName!=\"Mitchell\"]['percent correct'].mean()\n",
        "  if other > mitchell:\n",
        "    title = title + f\"Congratulations {teamName}\\nYou Defeated Mitchell! {p}\"\n",
        "  else:\n",
        "    title = title + f\"Sorry {teamName}\\nMitchell Wins {p}\"\n",
        "\n",
        "  ax = sns.barplot(data=results, x=\"teamName\", y=\"percent correct\", ax=ax);\n",
        "  if score==\"individual\":\n",
        "    ax.set_ylim([.5,0.85]);\n",
        "  else:\n",
        "    ax.set_ylim([.5,0.95]);\n",
        "\n",
        "  ax.set_ylabel(ylabel, fontsize=24);\n",
        "  ax.set_xlabel(\"team name\", fontsize=24);\n",
        "  ax.set_title(title, fontsize=22);\n",
        "  ax.yaxis.labelpad = 20\n",
        "  ax.xaxis.labelpad = 20\n",
        "  ax.title.set_position([.5, 1.02])\n",
        "\n",
        "  return ax;"
      ],
      "metadata": {
        "id": "K-mPsdEE4Q77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from fastprogress import progress_bar\n",
        "from functools import lru_cache\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "@lru_cache()\n",
        "def get_voxel_data(folder='./brain_data', brain_subjects=[1,2,3,4,5,6,7,8,9]):\n",
        "  data = dict()\n",
        "  for brain_sub in progress_bar(brain_subjects):\n",
        "    brain_data = sio.loadmat(os.path.join(folder, f'data-science-P{brain_sub}_converted.mat'),\n",
        "                             squeeze_me=True,\n",
        "                             struct_as_record=True, \n",
        "                             simplify_cells=True)\n",
        "    data[brain_sub] = dict(\n",
        "        meta=brain_data['meta'],\n",
        "        sortIdx=brain_data['sortIdx'],\n",
        "        voxelReliability=brain_data['voxelReliability']\n",
        "    )\n",
        "  return data\n",
        "\n",
        "def get_gray_matter_cube(brain_data, brain_subjects=[1,2,3,4,5,6,7,8,9]):\n",
        "  brainCube = []\n",
        "  for brain_sub in brain_subjects:\n",
        "    cube = np.zeros((51, 61, 23))\n",
        "    meta = brain_data[brain_sub]['meta']\n",
        "    usedVoxels = meta['coordToCol']\n",
        "    cube = np.zeros(usedVoxels.shape)\n",
        "    cube[usedVoxels>0] = .15\n",
        "    brainCube.append(cube)\n",
        "  brainCube = np.stack(brainCube, axis=3)\n",
        "  return brainCube\n",
        "\n",
        "@lru_cache()\n",
        "def get_reliable_cube(brain_data, num_voxels, \n",
        "                      brain_subjects=[1,2,3,4,5,6,7,8,9]):\n",
        "  dataCube = []\n",
        "  \n",
        "  for brain_sub in progress_bar(brain_subjects):\n",
        "    meta = brain_data[brain_sub]['meta']\n",
        "    idxs = brain_data[brain_sub]['sortIdx'][0:num_voxels]\n",
        "    usedVoxels = np.isin(meta['coordToCol'], idxs)\n",
        "    cube = np.zeros(usedVoxels.shape)\n",
        "    cube[usedVoxels] = 1\n",
        "    dataCube.append(cube)\n",
        "\n",
        "  dataCube = np.stack(dataCube, axis=3)\n",
        "\n",
        "  return dataCube \n",
        "\n",
        "def get_data_cube(betas, feature_index, brain_data, num_voxels, \n",
        "                  brain_subjects=[1,2,3,4,5,6,7,8,9]):\n",
        "  dataCube = []\n",
        "  \n",
        "  for brain_sub in progress_bar(brain_subjects):\n",
        "    meta = brain_data[brain_sub]['meta']    \n",
        "    idxs = brain_data[brain_sub]['sortIdx'][0:num_voxels]\n",
        "    weights = betas[brain_sub-1][0:num_voxels, feature_index]\n",
        "    usedVoxels = [np.where(meta['coordToCol']==idx) for idx in idxs]\n",
        "    usedVoxels = tuple(np.concatenate(x) for x in zip(*usedVoxels))\n",
        "    cube = np.zeros(meta['coordToCol'].shape)\n",
        "    cube[usedVoxels] = weights\n",
        "    dataCube.append(cube)\n",
        "\n",
        "  dataCube = np.stack(dataCube, axis=3)\n",
        "\n",
        "  return dataCube \n",
        "\n",
        "def data_cube_to_color_cube(dataCube, scale_factor=None, binarize=False):\n",
        "  mask = np.ones(dataCube.shape)  \n",
        "  if scale_factor is None:\n",
        "    vals = dataCube[dataCube != 0]\n",
        "    M = np.median(vals)\n",
        "    MDM = np.abs(vals-M).mean()\n",
        "    scale_factor = 1.96*MDM \n",
        "  \n",
        "  # positive weight color range\n",
        "  rgbPosU=np.array([255, 255, 0])\n",
        "  rgbPosL=np.array([243, 193, 121])/1.5\n",
        "\n",
        "  # negative weight color range\n",
        "  rgbNegL=np.array([192, 211, 255])/1.5\n",
        "  rgbNegU=np.array([0, 75, 255])\n",
        "\n",
        "  # initialize the R, G, B color cubes\n",
        "  colCubeR=np.zeros(dataCube.shape)\n",
        "  colCubeG=np.zeros(dataCube.shape)\n",
        "  colCubeB=np.zeros(dataCube.shape)\n",
        "\n",
        "  # set negative colors\n",
        "  cube=dataCube.copy()\n",
        "  negIDX=cube<0;\n",
        "  posIDX=cube>0;\n",
        "  cube[posIDX]=0\n",
        "  cube=np.abs(cube)\n",
        "  # sf=.50\n",
        "  # sf = np.abs(dataCube).max()\n",
        "  # sf = .10\n",
        "  idx=negIDX\n",
        "\n",
        "  # rescale the weights by scale_factor\n",
        "  cubeR=(cube-cube.min()) / scale_factor\n",
        "  cubeR[cubeR>1]=1\n",
        "  if binarize: cubeR[cubeR>0]=1;\n",
        "  newR = (cubeR[idx]*rgbNegU[0]) + ( (1-cubeR[idx])*rgbNegL[0] )\n",
        "  colCubeR[idx]=colCubeR[idx]+newR*mask[idx]\n",
        "\n",
        "  cubeG=(cube-cube.min()) / scale_factor\n",
        "  cubeG[cubeG>1]=1\n",
        "  if binarize: cubeG[cubeG>0]=1\n",
        "  newG = (cubeG[idx]*rgbNegU[1]) + ( (1-cubeG[idx])*rgbNegL[1] )\n",
        "  colCubeG[idx]=colCubeG[idx]+newG*mask[idx]\n",
        "\n",
        "  cubeB=(cube-cube.min()) / scale_factor\n",
        "  cubeB[cubeB>1]=1\n",
        "  if binarize: cubeB[cubeB>0]=1\n",
        "  newB = (cubeB[idx]*rgbNegU[2]) + ( (1-cubeB[idx])*rgbNegL[2] )\n",
        "  colCubeB[idx]=colCubeB[idx]+newB*mask[idx]\n",
        "\n",
        "  # set positive colors\n",
        "  cube=dataCube.copy()\n",
        "  cube[negIDX]=0\n",
        "  idx=posIDX;\n",
        "\n",
        "  cubeR=(cube-cube.min()) / scale_factor\n",
        "  cubeR[cubeR>1]=1;\n",
        "  if binarize: cubeR[cubeR>0]=1;\n",
        "  newR = (cubeR[idx]*rgbPosU[0]) + (1-cubeR[idx])*rgbPosL[0]\n",
        "  colCubeR[idx]=colCubeR[idx]+newR*mask[idx]\n",
        "\n",
        "  cubeG=(cube-cube.min()) / scale_factor\n",
        "  cubeG[cubeG>1]=1\n",
        "  if binarize: cubeG[cubeG>0]=1\n",
        "  newG = (cubeG[idx]*rgbPosU[1]) + (1-cubeG[idx])*rgbPosL[1]\n",
        "  colCubeG[idx]=colCubeG[idx]+newG*mask[idx]\n",
        "\n",
        "  cubeB=(cube-cube.min()) / scale_factor\n",
        "  cubeB[cubeB>1]=1\n",
        "  if binarize: cubeB[cubeB>0]=1\n",
        "  newB = (cubeB[idx]*rgbPosU[2]) + (1-cubeB[idx])*rgbPosL[2]\n",
        "  colCubeB[idx]=colCubeB[idx]+newB*mask[idx]\n",
        "\n",
        "  return colCubeR, colCubeG, colCubeB\n",
        "\n",
        "def quick_view_cube(dataCube):\n",
        "  a, b, c = dataCube.shape\n",
        "  n = int(np.ceil(np.sqrt(c)))\n",
        "\n",
        "  fig, axs = plt.subplots(n, n, figsize=(n*4,n*4))\n",
        "  i = -1\n",
        "  for row in axs:\n",
        "    for ax in row:\n",
        "      i+=1\n",
        "      if i < c:\n",
        "        data_slice = dataCube[:,:,i]\n",
        "        img = np.repeat(data_slice[:,:,np.newaxis],3,axis=2)\n",
        "        ax.imshow(img, vmin=0, vmax=1)\n",
        "        ax.axis('off')\n",
        "      else:\n",
        "        ax.remove()\n",
        "\n",
        "def quickViewCubeOverlay(brainCube,dataCube,scale_factor=None, binarize=False,\n",
        "                         brain_lum=.20, title=''):\n",
        "  R, G, B = data_cube_to_color_cube(dataCube,\n",
        "                                    binarize=binarize,\n",
        "                                    scale_factor=scale_factor)\n",
        "  a, b, c = dataCube.shape\n",
        "  n = int(np.ceil(np.sqrt(c)))\n",
        "\n",
        "  fig, axs = plt.subplots(n, n, figsize=(n*4,n*4))\n",
        "  i = -1\n",
        "  for row in axs:\n",
        "    for ax in row:\n",
        "      i+=1\n",
        "      if i < c:\n",
        "        brain_slice = brainCube[:,:,i]\n",
        "        brain_slice = brain_slice / brainCube.max() * brain_lum\n",
        "        img = np.zeros((*brain_slice.shape,3))\n",
        "        img[:,:,0]=brain_slice*255 + R[:,:,i]*(1-brain_lum)\n",
        "        img[:,:,1]=brain_slice*255 + G[:,:,i]*(1-brain_lum)\n",
        "        img[:,:,2]=brain_slice*255 + B[:,:,i]*(1-brain_lum)   \n",
        "\n",
        "        if img.max() > 0: \n",
        "          img = img/255.0\n",
        "        ax.imshow(img)\n",
        "        #ax.axis('off')\n",
        "\n",
        "        if (i==0): \n",
        "          ax.set_title('bottom of brain', fontsize=16)\n",
        "          ax.set_ylabel('back of brain', fontsize=16)\n",
        "\n",
        "        if (i%n*4)==0:\n",
        "          ax.set_ylabel('back of brain', fontsize=16)\n",
        "\n",
        "        if (i==(c-1)): \n",
        "          ax.set_title('top of brain', fontsize=16)\n",
        "\n",
        "        ax.tick_params(\n",
        "          axis='both',       # changes apply to the x-axis & y-axis\n",
        "          which='both',      # both major and minor ticks are affected\n",
        "          bottom=False,      # ticks along the bottom edge are off\n",
        "          top=False,         # ticks along the top edge are off\n",
        "          left=False,\n",
        "          right=False,\n",
        "          labelbottom=False, # labels along the bottom edge are off\n",
        "          labelleft=False)   # labels along the left edge are off\n",
        "\n",
        "      else:\n",
        "        ax.remove()\n",
        "\n",
        "  fig.suptitle(title, fontsize=24, y=0.90)"
      ],
      "metadata": {
        "id": "TN_qv3Du4UZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### analysis steps"
      ],
      "metadata": {
        "id": "YWFhryAQ97Vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import scipy.io as sio\n",
        "\n",
        "def step0_prepare_rating_data(teamName, dropRaters=[], dropFeatures=[]):  \n",
        "  \n",
        "  download_ratings(teamName, dropRaters=dropRaters, dropFeatures=dropFeatures)\n",
        "\n",
        "  feature_data = get_feature_data(teamName)\n",
        "\n",
        "  folder = os.path.join(drive, 'FeatureData')\n",
        "  if not os.path.exists(folder):\n",
        "    os.makedirs(folder)\n",
        "\n",
        "  filename = os.path.join(folder, f'{teamName}_Features.pth.tar')\n",
        "  torch.save(feature_data, filename)\n",
        "\n",
        "  filename = os.path.join(folder, f'{teamName}_Features.mat')\n",
        "  sio.savemat(filename, feature_data)"
      ],
      "metadata": {
        "id": "raJT-2wMtflS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def step1_fit_feature_model(teamName, num_voxels=500, \n",
        "                            brain_subjects=[1], \n",
        "                            testIndividualFeatures=False):\n",
        "  results = run_full_analysis(teamName, \n",
        "                              num_voxels=num_voxels,\n",
        "                              sub_list=brain_subjects,\n",
        "                              testIndividualFeatures=testIndividualFeatures)\n",
        "\n",
        "  pprint(compute_prediction_summary(results['df'],\n",
        "                                    'brain_prediction',\n",
        "                                    'encoding_model',\n",
        "                                    'combo'))\n",
        "  save_full_results(results)"
      ],
      "metadata": {
        "id": "jQRmGoXn0fLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def step2_brain_prediction_accuracy(teamName, \n",
        "                           num_voxels=500, \n",
        "                           method=\"encoding_model\",\n",
        "                           score=\"combo\"):\n",
        "\n",
        "  ax = compare_to_mitchell(teamName, \n",
        "                           num_voxels=num_voxels, \n",
        "                           task=\"brain_prediction\",\n",
        "                           method=method,\n",
        "                           score=score,\n",
        "                           title=\"Predicting Brain Activity from Features\\n\")\n",
        "\n",
        "  return ax;"
      ],
      "metadata": {
        "id": "bU5gxXC137cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_results_by_feature(teamName,\n",
        "                           num_voxels=500,\n",
        "                           task=\"brain_prediction\",\n",
        "                           method=\"encoding_model\",\n",
        "                           score=\"individual\"):\n",
        "  \n",
        "  # save file \n",
        "  folder = os.path.join(drive,'Results-ByFeature')\n",
        "  if not os.path.exists(folder): os.makedirs(folder)\n",
        "  filename = os.path.join(folder, \n",
        "                          f'{teamName}_{num_voxels}_results_by_feature.csv')\n",
        "  \n",
        "  if os.path.isfile(filename):\n",
        "    results = pd.read_csv(filename)\n",
        "  else:\n",
        "    files = glob(os.path.join(drive, f'./Results-BrainPrediction/*{teamName}*{num_voxels}*features*'))\n",
        "    assert len(files)==1, f\"Oops, expected 1 file, got {len(files)}\"\n",
        "    df = torch.load(files[0])['feat_df']\n",
        "    features = sorted(df.feat_name.unique())\n",
        "    subjects = sorted(df.brain_subject.unique())\n",
        "    results = defaultdict(list)\n",
        "    for feature in features:\n",
        "      for subject in subjects:      \n",
        "        subset = df[(df.feat_name==feature) & (df.brain_subject==subject) & \n",
        "                    (df.task==task) & (df.method==method) & (df.scoring==score)]\n",
        "        assert len(subset)==1770, f\"Oops, expected 1770 scores, got {len(subset)}\"\n",
        "        results['feature'].append(feature)\n",
        "        results['subject'].append(subject)\n",
        "        results['percent correct'].append(subset.correct.mean())\n",
        "    results = pd.DataFrame(results)\n",
        "    results.to_csv(filename, index=False)\n",
        "\n",
        "  return results  \n",
        "\n",
        "def step3_determine_best_feature(teamName,\n",
        "                                 num_voxels=500, \n",
        "                                 task=\"brain_prediction\",\n",
        "                                 method=\"encoding_model\",\n",
        "                                 score=\"individual\"):\n",
        "  \n",
        "  results = get_results_by_feature(teamName,\n",
        "                                 num_voxels=500, \n",
        "                                 task=\"brain_prediction\",\n",
        "                                 method=\"encoding_model\",\n",
        "                                 score=\"individual\")\n",
        "  \n",
        "  sort_order = results.groupby(\"feature\").mean().sort_values(\"percent correct\", ascending=False).index\n",
        "  features = sorted(results. feature.unique())\n",
        "\n",
        "  sns.set(rc={\n",
        "      'figure.figsize':(14,len(features)*.5),\n",
        "      'axes.grid': False,\n",
        "  })\n",
        "  sns.set(font_scale = 1.5)\n",
        "  sns.set_style(\"white\")\n",
        "\n",
        "  ax = sns.barplot(data=results, y=\"feature\", x=\"percent correct\", \n",
        "                  order=sort_order, orient = 'h')\n",
        "\n",
        "  ax.set_xlim([.45,0.85]);\n",
        "  ax.set_xlabel(\"percent correct\", fontsize=24);\n",
        "  ax.set_ylabel(\"feature name\", fontsize=24);\n",
        "  ax.set_title(\"Accuracy using each individual feature on its own\", fontsize=22);\n",
        "  ax.yaxis.labelpad = 20\n",
        "  ax.xaxis.labelpad = 20\n",
        "  ax.title.set_position([.5, 1.02])\n"
      ],
      "metadata": {
        "id": "F4dg512I-E11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "from functools import lru_cache\n",
        "from pprint import pprint \n",
        "\n",
        "def get_feature_names(teamName, num_voxels=500):\n",
        "  # get feature-modeling results for this team\n",
        "  results = get_feature_modeling_results(teamName, num_voxels=num_voxels)\n",
        "  betas = results['betas']\n",
        "  featureNames = results['feature_data']['featureNames'].tolist()\n",
        "  pprint(featureNames)\n",
        "\n",
        "def get_feature_modeling_results(teamName, num_voxels=500):\n",
        "  files = glob(os.path.join(drive, 'Results-BrainPrediction', f'*{teamName}*{num_voxels}*'))\n",
        "  assert len(files)==1, f\"Oops, expected 1 file, got {len(files)}\"\n",
        "  filename = files[0]\n",
        "  print(filename)\n",
        "  results = torch.load(filename)\n",
        "\n",
        "  return results \n",
        "\n",
        "def step4_visualize_feature_weights(teamName, featureName, num_voxels=500, \n",
        "                                    scaling='relative', binarize=False):\n",
        "  \n",
        "  # get feature-modeling results for this team\n",
        "  results = get_feature_modeling_results(teamName, num_voxels=num_voxels)\n",
        "  betas = results['betas']\n",
        "  featureNames = results['feature_data']['featureNames'].tolist()\n",
        "  print(featureNames)\n",
        "  \n",
        "  # get gray matter mask for neural data\n",
        "  brain_data = get_voxel_data()\n",
        "  brainCube = get_gray_matter_cube(brain_data)\n",
        "  brain_data.keys(), brainCube.shape\n",
        "\n",
        "  # get weights for featureName\n",
        "  feature_index = featureNames.index(featureName)\n",
        "  dataCube = get_data_cube(betas, feature_index, brain_data, \n",
        "                           num_voxels=num_voxels)\n",
        "\n",
        "  # get scaling factor\n",
        "  scale_factor = None\n",
        "  if scaling=='absolute':\n",
        "    all_betas = np.stack(betas).mean(axis=0)\n",
        "    vals = np.abs(all_betas[all_betas!=0])\n",
        "    M = np.median(vals)\n",
        "    MAD = (vals-M).mean() \n",
        "    scale_factor = MAD*3\n",
        "  \n",
        "  # finally, plot it\n",
        "  ax = quickViewCubeOverlay(brainCube.mean(axis=3),dataCube.mean(axis=3),\n",
        "                            scale_factor=scale_factor, binarize=False,\n",
        "                            title=f'Feature Weights for {featureName}')\n",
        "  \n",
        "  return ax"
      ],
      "metadata": {
        "id": "ELNlCcmt-kpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def step5_mind_reading_accuracy(teamName, \n",
        "                                num_voxels=500, \n",
        "                                method=\"botastic_templates\",\n",
        "                                score=\"combo\"):\n",
        "\n",
        "  ax = compare_to_mitchell(teamName, \n",
        "                           num_voxels=num_voxels, \n",
        "                           task=\"mind_reading\",\n",
        "                           method=method,\n",
        "                           score=score,\n",
        "                           title=\"Mind Reading\\n\")\n",
        "\n",
        "  return ax;"
      ],
      "metadata": {
        "id": "_P2Od0AB-mWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def step6_brain_prediction_same_diff_category(teamName, \n",
        "                                              num_voxels=500, \n",
        "                                              method=\"encoding_model\",\n",
        "                                              score=\"combo\"):\n",
        "\n",
        "  fig,(ax1,ax2) =  plt.subplots(1,2, figsize=(16,8))\n",
        "\n",
        "  compare_to_mitchell(teamName,\n",
        "                      num_voxels=num_voxels, \n",
        "                      task=\"brain_prediction\",\n",
        "                      method=method,\n",
        "                      score=score,\n",
        "                      accuracy=\"accuracySameCat\",\n",
        "                      title=\"Brain-Prediction Same-Category\\n\",\n",
        "                      ax=ax1)\n",
        "\n",
        "  compare_to_mitchell(teamName,\n",
        "                      num_voxels=num_voxels, \n",
        "                      task=\"brain_prediction\",\n",
        "                      method=method,\n",
        "                      score=score,\n",
        "                      accuracy=\"accuracyDiffCat\",\n",
        "                      title=\"Brain-Prediction Diff-Category\\n\",\n",
        "                      ax=ax2, ylabel=\"\")\n",
        "  \n",
        "  plt.show()\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "aQ8cYOa--n94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def step7_mind_reading_same_diff_category(teamName, \n",
        "                                          num_voxels=500, \n",
        "                                          method=\"botastic_templates\",\n",
        "                                          score=\"combo\"):\n",
        "\n",
        "  fig,(ax1,ax2) =  plt.subplots(1,2, figsize=(16,8))\n",
        "\n",
        "  compare_to_mitchell(teamName,\n",
        "                      num_voxels=num_voxels, \n",
        "                      task=\"mind_reading\",\n",
        "                      method=method,\n",
        "                      score=score,\n",
        "                      accuracy=\"accuracySameCat\",\n",
        "                      title=\"Mind-Reading Same-Category\\n\",\n",
        "                      ax=ax1)\n",
        "\n",
        "  compare_to_mitchell(teamName,\n",
        "                      num_voxels=num_voxels, \n",
        "                      task=\"mind_reading\",\n",
        "                      method=method,\n",
        "                      score=score,\n",
        "                      accuracy=\"accuracyDiffCat\",\n",
        "                      title=\"Mind-Reading Diff-Category\\n\",\n",
        "                      ax=ax2, ylabel=\"\")\n",
        "  \n",
        "  plt.show()\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "SCiYDGel-pv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# run analyses\n",
        "\n",
        "This notebook shows you the results of two different \"brain decoding\" analyses (brain-prediction and mind-reading), where your feature ratings were used to analyze the neural responses of Mitchell's fMRI participants.\n",
        "\n",
        "**Brain-prediction:**\n",
        "\n",
        "This is where you go toe-to-toe with Mitchell in his original \"*predict brain activation from features*\" analysis. The goal with brain prediction is to train a feature model to learn what each voxel in the brain responds to. Then, for held out items, whose features are known, predict the brain activation for the held out items.\n",
        "\n",
        "**Mind-reading:**\n",
        "\n",
        "We can think of this as \"inverting\" the brain prediction analysis. Mitchell learned how each voxel was influenced by each feature, and used that to predict neural resposnes based on an items features.\n",
        "\n",
        "Here, we flip it. Instead we will take the brain response, and use it to predict the features! Then, from predicted features, we'll guess which object was observed (whichever object's true features correlates the most with the predicted features).\n"
      ],
      "metadata": {
        "id": "IMovYKmKq8ej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step0_prepare_rating_data\n",
        "\n",
        "Prepare your rating data for analysis."
      ],
      "metadata": {
        "id": "nQcPpCEgq-Jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teamName = 'v1report'\n",
        "dropFeatures = ['color2_Blue',\n",
        "                'color2_Brown', 'color2_Clear', 'color2_Green ', 'color2_Grey', \n",
        "                'color2_Orange', 'color2_Red', 'color2_White', 'color2_Yellow',\n",
        "                'interaction_nose']\n",
        "step0_prepare_rating_data(teamName, dropFeatures=dropFeatures)"
      ],
      "metadata": {
        "id": "k5X9NAnrrC7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step1_fit_feature_model\n",
        "\n",
        "Fit the feature model (training on all possible leave-2-out pairs for 60 objects = 1770 iterations x 9 fMRI subjects!). This will take a few minutes..."
      ],
      "metadata": {
        "id": "IZPMIFPnzxid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "step1_fit_feature_model(teamName, brain_subjects=[1,2,3,4,5,6,7,8,9])"
      ],
      "metadata": {
        "id": "-nEyjxSWzx1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step2_brain_prediction_accuracy\n",
        "\n",
        "Compare your team’s model to Mitchell’s on brain-prediction!  \n",
        "**Did you win? Put the graph in your lab book with a note about what you think it means (e.g., If you lost, do you think your features were \"the wrong features\", or that your feature ratings were just too noisy?. If you think your features were the wrong features, what did mitchell get right that you got wrong? Or, if you won, which of your features do you think carried you past Mitchell's feature model? The following steps may help you answer these questions.)**"
      ],
      "metadata": {
        "id": "IBEtl40Ezu6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "step2_brain_prediction_accuracy(teamName);"
      ],
      "metadata": {
        "id": "jyIdpE0C7qgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step3_determine_best_feature\n",
        "\n",
        "Determine which of your individual features was the best predictor of brain activation patterns. P**ut the graph in your lab book with a note about what you think it means. (You could also compare to Mitchell’s best feature. His team name is ‘MitchellSemantic’).**"
      ],
      "metadata": {
        "id": "4Afs-GDz9szZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# skipping this step in this notebook!\n",
        "# step3_determine_best_feature(teamName)"
      ],
      "metadata": {
        "id": "bq929cxc9toT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step4_visualize_feature_weights\n",
        "\n",
        "It would be interesting to know which voxels got high weights and which one’s got low weights, and where the high and low weights were in the brain. One way to do that is to visualize the weights in “slices”.  Next answer these questions: Where are the voxels used in our analysis located in the brain? Where are the high weights? Where are the low weights? Does your “best feature” have a different pattern than your “worst feature” (e.g., does it seem more disorganized and random, or does it have hot/cold spots in different places?). **Put some figures in your lab book with comments (just a couple, no need to look at all your features, unless you want to).**"
      ],
      "metadata": {
        "id": "En6rhpiS-zR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get_feature_names(teamName)"
      ],
      "metadata": {
        "id": "nqkRfvuL-4Dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step4_visualize_feature_weights(teamName, featureName='size')"
      ],
      "metadata": {
        "id": "I3s3igdV-JB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step5_mind_reading_accuracy\n",
        "\n",
        "OK, it’s time to Riverside it (that’s a sports/football term, meaning to change directions on the field). In our case, that means instead of using feature data to predict brain data, we’re going to use brain data to predict feature data. In other words, we want to know whether you can measure someone’s brain activity, use those brain patterns to predict the features of the object, and therefore to determine which object the person was looking at/thinking about. In theory, we can determine what object a person is looking at/thinking about, even if this is the first time we’ve ever measured their brain activity for that item! This is real mind reading, using a “model of how the brain encodes information” to read someone's state of mind (features ~= state of mind).\n",
        "\n",
        "In this section, we’re going beyond Mitchell’s published work (beyond the cutting edge...that’s fun). Mitchell never did mind reading proper, as we’re about to, so we have to apply our methods to his data for comparison. Conceptually, we’re using the same “leave 2 out” procedure (train on 58 items, test on the remaining 2; repeat 1770 times). But now we’re mapping voxel activations to features values, so we can classify which object was seen from brain activation patterns.\n",
        "\n",
        "**How well does it work? Put the graph in your lab book with a note about what you think it means.**"
      ],
      "metadata": {
        "id": "8S-TdE6__tYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "step5_mind_reading_accuracy(teamName);"
      ],
      "metadata": {
        "id": "_WPYNhEb_SGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step6_brain_prediction_same_diff_category\n",
        "\n",
        "Whose model does better on brain-prediction with “within-category” vs. \"different-category\" discriminations, your model or Mitchell’s?\n"
      ],
      "metadata": {
        "id": "VXQ50hPC_2cS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "step6_brain_prediction_same_diff_category(teamName);"
      ],
      "metadata": {
        "id": "iYJfs2aV_uX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step7_mind_reading_same_diff_category\n",
        "\n",
        "Whose model does better on mind-reading with “within-category” vs. \"different-category\" discriminations, your model or Mitchell’s?\n",
        "\n"
      ],
      "metadata": {
        "id": "zPK7HVYw_6Qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "step7_mind_reading_same_diff_category(teamName);"
      ],
      "metadata": {
        "id": "VB09IUdO_9so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wrap it up!\n",
        "\n",
        "Wrap up your lab book with a few parting thoughts. Where were you successful? What could you do to improve your feature model, and it’s ability to predict brain data, and/or your ability to do mind reading from brain data?"
      ],
      "metadata": {
        "id": "ON9n7o2gN9Ne"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Um0Pzxs2EI8y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}