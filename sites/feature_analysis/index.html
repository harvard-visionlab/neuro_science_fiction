<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Feature Analysis - Neuroscience Fiction</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>Feature Analysis</h1>
            <p class="subtitle">Analyze your feature ratings to optimize your brain prediction model</p>
        </header>

        <!-- Progress Indicator -->
        <div class="progress-indicator">
            <div class="progress-step active" data-step="1">
                <div class="step-number">1</div>
                <div class="step-label">Load Data</div>
            </div>
            <div class="progress-step" data-step="2">
                <div class="step-number">2</div>
                <div class="step-label">Reliability</div>
            </div>
            <div class="progress-step" data-step="3">
                <div class="step-number">3</div>
                <div class="step-label">Agreement</div>
            </div>
            <div class="progress-step" data-step="4">
                <div class="step-number">4</div>
                <div class="step-label">Redundancy</div>
            </div>
            <div class="progress-step" data-step="5">
                <div class="step-number">5</div>
                <div class="step-label">Similarity</div>
            </div>
            <div class="progress-step" data-step="6">
                <div class="step-number">6</div>
                <div class="step-label">Decisions</div>
            </div>
        </div>

        <!-- Step 1: Load Data -->
        <section class="step-section active" id="step1">
            <div class="card">
                <div class="step-header">
                    <h2>Step 1: Load Your Ratings Data</h2>
                </div>

                <div class="explanation">
                    <p>Let's start by loading your feature ratings from the server. You'll need your <strong>year</strong> and <strong>group name</strong>.</p>
                    <p class="note">Your ratings may include both human raters and LLM models (surrogate raters like GPT-5 or Gemini).</p>
                </div>

                <div class="input-section">
                    <div class="input-group">
                        <label for="yearInput">Year:</label>
                        <input type="text" id="yearInput" placeholder="e.g., 2025" value="2025">
                    </div>
                    <div class="input-group">
                        <label for="groupNameInput">Group Name:</label>
                        <input type="text" id="groupNameInput" placeholder="e.g., YourGroupName">
                    </div>
                    <button id="loadDataBtn" class="btn-primary">Load Data</button>
                </div>

                <div id="loadingIndicator" class="loading-message" style="display: none;">
                    <div class="spinner"></div>
                    <p>Loading your ratings data...</p>
                </div>

                <div id="dataLoadError" class="error-message" style="display: none;"></div>

                <div id="dataSummary" class="data-summary" style="display: none;">
                    <h3>Data Loaded Successfully!</h3>
                    <div class="summary-grid">
                        <div class="summary-item">
                            <div class="summary-label">Items:</div>
                            <div class="summary-value" id="numItems">0</div>
                        </div>
                        <div class="summary-item">
                            <div class="summary-label">Features:</div>
                            <div class="summary-value" id="numFeatures">0</div>
                        </div>
                        <div class="summary-item">
                            <div class="summary-label">Raters:</div>
                            <div class="summary-value" id="numRaters">0</div>
                        </div>
                        <div class="summary-item">
                            <div class="summary-label">Total Ratings:</div>
                            <div class="summary-value" id="totalRatings">0</div>
                        </div>
                    </div>

                    <div style="text-align: center; margin: 20px 0;">
                        <button id="downloadLoadedDataBtn" class="btn-download">Download Loaded Data (CSV)</button>
                    </div>

                    <div id="exclusionWarning" class="note" style="display: none; margin: 20px 0;">
                        <strong>⚠️ Exclusions Updated:</strong> Previous analysis results have been cleared. Re-run Steps 2-5 to analyze the filtered dataset.
                    </div>

                    <details class="exclusion-section" id="raterExclusionSection">
                        <summary>Exclude Raters (Optional)</summary>
                        <p class="explanation-text">Check raters to exclude them from all analyses. Useful for removing raters with low agreement or incomplete data.</p>
                        <div id="raterExclusionList" class="exclusion-list"></div>
                    </details>

                    <details class="exclusion-section" id="featureExclusionSection">
                        <summary>Exclude Features (Optional)</summary>
                        <p class="explanation-text">Check features to exclude them from all analyses. Useful for removing features with poor reliability or high redundancy.</p>
                        <div id="featureExclusionList" class="exclusion-list"></div>
                    </details>

                    <div id="droppedRatersSection" class="dropped-raters-section" style="display: none;">
                        <h4>⚠️ Raters Excluded (Incomplete Ratings):</h4>
                        <p class="explanation-text">The following raters were excluded because they didn't complete all ratings:</p>
                        <div id="droppedRatersList" class="dropped-raters-list"></div>
                    </div>

                    <div class="rater-breakdown">
                        <h4>Active Raters:</h4>
                        <div id="raterList" class="rater-list"></div>
                    </div>

                    <details class="data-preview">
                        <summary>Preview Data (first 10 rows)</summary>
                        <div id="dataPreviewTable"></div>
                    </details>
                </div>

                <div class="step-navigation">
                    <button id="step1Next" class="btn-next" disabled>Next: Feature Reliability →</button>
                </div>
            </div>
        </section>

        <!-- Step 2: Feature Reliability -->
        <section class="step-section" id="step2">
            <div class="card">
                <div class="step-header">
                    <h2>Step 2: Feature Reliability</h2>
                </div>

                <div class="explanation">
                    <h3>What is Feature Reliability?</h3>
                    <p><strong>Also known as "Inter-rater Agreement"</strong>, this measures how consistently different raters (humans and LLMs) agreed on the ratings for each feature.</p>

                    <details>
                        <summary>How does it work?</summary>
                        <div class="explanation-detail">
                            <p><strong>For each feature separately:</strong></p>
                            <ol>
                                <li>Take all items rated by Rater 1 (e.g., 60 ratings)</li>
                                <li>Take all items rated by Rater 2 (e.g., 60 ratings)</li>
                                <li>Correlate these two 60-element vectors</li>
                                <li>Repeat for all pairs of raters</li>
                                <li>Average these pairwise correlations to get reliability for this feature</li>
                            </ol>
                            <p><strong>Example:</strong> If you have 60 items and 5 raters, for the feature "animacy" we correlate each rater's 60 item ratings with every other rater's 60 item ratings (10 pairs total), then average those 10 correlations.</p>
                            <p><strong>Higher values = better reliability</strong> (raters agreed more on this feature)</p>
                            <p>Features with low reliability (&lt; 0.5) may be subjective or poorly defined.</p>
                        </div>
                    </details>

                    <div class="note">
                        <strong>Note on Feature Reliability:</strong>There are many possible sources of disagreement 
                        between raters. Humans are often "noisy" reponders (the same person might answer the 
                        same question differently at different times), while deterministic LLMs (temperature=0) might 
                        have perfect self-consistency. So human-human, and human-LLM differences can arise just 
                        due to "human noisyiness". But there can also be "real disagreements" between raters (whether human
                        or LLM), and this too will decrease the relability of a feature. Whatever the source of variation,
                        features that vary between raters are also like to vary amongst your brain subjects, and so 
                        will tend to be less useful features for brain prediction.
                    </div>
                </div>

                <div id="reliabilityAnalysis">
                    <button id="computeReliabilityBtn" class="btn-primary">Compute Feature Reliability</button>

                    <div id="reliabilityLoading" class="loading-message" style="display: none;">
                        <div class="spinner"></div>
                        <p>Computing correlations...</p>
                    </div>

                    <div id="reliabilityResults" style="display: none;">
                        <div class="results-header">
                            <h3>Feature Reliability Results</h3>
                            <button id="downloadReliabilityChart" class="btn-download">Download Chart (PNG)</button>
                        </div>

                        <div class="chart-container">
                            <canvas id="reliabilityChart"></canvas>
                        </div>

                        <details class="data-table-section">
                            <summary>View Data Table</summary>
                            <div id="reliabilityTable"></div>
                        </details>

                        <div class="interpretation">
                            <h4>Interpretation Guide:</h4>
                            <ul>
                                <li><strong>r &gt; 0.7:</strong> Excellent reliability - strong agreement</li>
                                <li><strong>r = 0.5-0.7:</strong> Good reliability - moderate agreement</li>
                                <li><strong>r = 0.3-0.5:</strong> Fair reliability - consider reviewing feature definition</li>
                                <li><strong>r &lt; 0.3:</strong> Poor reliability - feature may be too subjective</li>
                                <li><strong>NaN (Not a Number):</strong> No variance - all raters gave identical ratings for this feature across all items. This means the feature doesn't discriminate between items in your dataset.</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="step-navigation">
                    <button id="step2Prev" class="btn-prev">← Previous</button>
                    <button id="step2Next" class="btn-next" disabled>Next: Rater Agreement →</button>
                </div>
            </div>
        </section>

        <!-- Step 3: Rater Agreement -->
        <section class="step-section" id="step3">
            <div class="card">
                <div class="step-header">
                    <h2>Step 3: Rater Agreement</h2>
                </div>

                <div class="explanation">
                    <h3>What is Rater Agreement?</h3>
                    <p>This analysis identifies which raters consistently agree with the group across all features. Unlike Step 2 which evaluates features, this evaluates individual rater performance.</p>

                    <details>
                        <summary>How does it work?</summary>
                        The goal is to give each rater a score indicating how well their ratings correlated with every other rater, on average.
                        <div class="explanation-detail">
                            <p><strong>For each rater_i:</strong></p>
                            <ol>
                                <li>Take the ratings for each feature one at a time (60 ratings, one per item)</li>
                                <li>Correlate rater_i's ratings with each other individual rater one by one</li>
                                <li>Compute the average correlation for rater_i with each of the other raters on this feature</li>
                                <li>This gives each rater an "agreement score" for this feature</li>
                            </ol>
                            <p><strong>Then across all features:</strong></p>
                            <ol start="4">
                                <li>Average each rater's agreement scores across all features</li>
                                <li>This gives each rater an overall agreement score</li>
                            </ol>
                            <p><strong>Example:</strong> If Rater 1 has 0.8 agreement on "animacy", 0.7 on "size", and 0.6 on "color", their overall agreement is (0.8+0.7+0.6)/3 = 0.70</p>
                            <p><strong>Higher values = better agreement</strong> with the group consensus</p>
                            <p>Low-agreement raters may be using different criteria or misunderstanding the task.</p>
                        </div>
                    </details>

                    <div class="note">
                        <strong>Note on LLM vs Human Raters:</strong> 
                        <ul>
                            <li>LLM models may show different agreement patterns because they are deterministic (no noise)</li>
                            <li>However, differences in "training data" or "reasoning ability" may lead LLM models to disagree systematically</li>                            
                            <li>Low agreement between humans and LLMs isn't necessarily bad - it may reflect different valid perspectives</li>
                            <li>While neither is necessarily more "objectively correct", since you are predicting human brain responses, when LLMs and humans disagree, the human judgments are probably more useful for your neural modeling.</li>
                        </ul>
                    </div>
                </div>

                <div id="agreementAnalysis">
                    <button id="computeAgreementBtn" class="btn-primary">Compute Rater Agreement</button>

                    <div id="agreementLoading" class="loading-message" style="display: none;">
                        <div class="spinner"></div>
                        <p>Computing rater-vs-rater correlations...</p>
                    </div>

                    <div id="agreementResults" style="display: none;">
                        <div class="results-header">
                            <h3>Rater Agreement Results</h3>
                            <button id="downloadAgreementChart" class="btn-download">Download Heatmap (PNG)</button>
                        </div>

                        <!-- Average Agreement Table -->
                        <div class="agreement-summary">
                            <h4>Average Agreement by Rater</h4>
                            <p class="explanation-text">This shows how well each rater correlates with all other raters, on average across all features.</p>
                            <div id="agreementSummaryTable"></div>
                        </div>

                        <!-- Heatmap -->
                        <div class="heatmap-section">
                            <h4>Rater-vs-Rater Correlation Heatmap</h4>
                            <p class="explanation-text">
                                Average correlation between each pair of raters across all features.
                                For each feature, we correlate Rater A's 60 item ratings with Rater B's 60 item ratings,
                                then average these correlations across all features.
                            </p>
                            <div id="agreementHeatmap" class="plotly-heatmap"></div>
                        </div>

                        <details class="data-table-section">
                            <summary>View Detailed Data Table</summary>
                            <div id="agreementDetailTable"></div>
                        </details>

                        <div class="interpretation">
                            <h4>Interpretation Guide:</h4>
                            <ul>
                                <li><strong>r &gt; 0.7:</strong> Excellent agreement - rater closely aligns with group</li>
                                <li><strong>r = 0.5-0.7:</strong> Good agreement - reasonable alignment</li>
                                <li><strong>r = 0.3-0.5:</strong> Fair agreement - some divergence from group</li>
                                <li><strong>r &lt; 0.3:</strong> Poor agreement - rater may be using different criteria</li>
                                <li><strong>NaN (zero-variance features):</strong> Features where all raters gave identical ratings for all items. These don't discriminate between items and are automatically excluded from agreement calculations.</li>
                                <li><strong>Consider dropping raters with consistently low agreement (&lt; 0.3)</strong></li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="step-navigation">
                    <button id="step3Prev" class="btn-prev">← Previous</button>
                    <button id="step3Next" class="btn-next" disabled>Next: Feature Redundancy →</button>
                </div>
            </div>
        </section>

        <!-- Step 4: Feature Redundancy -->
        <section class="step-section" id="step4">
            <div class="card">
                <div class="step-header">
                    <h2>Step 4: Feature Redundancy</h2>
                </div>

                <div class="explanation">
                    <h3>What is Feature Redundancy?</h3>
                    <p>Feature redundancy identifies features that are highly correlated with each other. Redundant features provide little additional information and can cause problems in regression models.</p>

                    <details>
                        <summary>How does it work?</summary>
                        <div class="explanation-detail">
                            <p><strong>For each item separately:</strong></p>
                            <ol>
                                <li>Average all raters' ratings for Feature 1 (e.g., "animacy")</li>
                                <li>Average all raters' ratings for Feature 2 (e.g., "size")</li>
                                <li>Correlate these two vectors across all items (e.g., 60 items)</li>
                                <li>Repeat for all pairs of features</li>
                            </ol>
                            <p><strong>Example:</strong> If "living" and "animacy" both have high ratings for dogs/cats and low ratings for rocks/chairs, they'll have high positive correlation (redundant).</p>
                            <p><strong>High correlation (> 0.9) = redundant features</strong></p>
                            <p>Consider dropping one feature from highly redundant pairs.</p>
                        </div>
                    </details>

                    <div class="note">
                        <strong>Why does this matter?</strong>
                        <ul>
                            <li>Redundant features waste effort in rating</li>
                            <li>Can cause multicollinearity problems in regression</li>
                            <li>Make it harder to interpret which features are important</li>
                            <li>Goal: Keep diverse, independent features</li>
                        </ul>
                    </div>
                </div>

                <div id="redundancyAnalysis">
                    <button id="computeRedundancyBtn" class="btn-primary">Compute Feature Redundancy</button>

                    <div id="redundancyLoading" class="loading-message" style="display: none;">
                        <div class="spinner"></div>
                        <p>Computing feature-vs-feature correlations...</p>
                    </div>

                    <div id="redundancyResults" style="display: none;">
                        <div class="results-header">
                            <h3>Feature Redundancy Results</h3>
                        </div>

                        <!-- Threshold Control -->
                        <div class="threshold-control">
                            <label for="redundancyThreshold">Redundancy Threshold (show pairs above):</label>
                            <input type="range" id="redundancyThreshold" min="0" max="1" step="0.05" value="0.7">
                            <span id="redundancyThresholdValue">0.70</span>
                            <p class="explanation-text">Pairs with absolute correlation above this threshold are considered redundant.</p>
                        </div>

                        <!-- Redundant Pairs Summary -->
                        <div id="redundantPairsSummary" class="data-summary"></div>

                        <!-- Heatmap -->
                        <div class="heatmap-section">
                            <h4>Feature-vs-Feature Correlation Heatmap</h4>
                            <div class="results-header">
                                <p class="explanation-text">
                                    Shows correlation between each pair of features (averaged ratings across all items).
                                    Darker red = strong positive correlation. Darker blue = strong negative correlation.
                                </p>
                                <button id="downloadRedundancyHeatmap" class="btn-download">Download Heatmap (PNG)</button>
                            </div>
                            <div id="redundancyHeatmap" class="plotly-heatmap"></div>
                        </div>

                        <!-- Bar Chart of Top Redundant Pairs -->
                        <div class="chart-section">
                            <h4>Most Redundant Feature Pairs</h4>
                            <div class="results-header">
                                <p class="explanation-text">
                                    Feature pairs sorted by absolute correlation (highest first).
                                    Only showing pairs above the threshold.
                                </p>
                                <button id="downloadRedundancyChart" class="btn-download">Download Chart (PNG)</button>
                            </div>
                            <div class="chart-container">
                                <canvas id="redundancyChart"></canvas>
                            </div>
                        </div>

                        <details class="data-table-section">
                            <summary>View All Feature Pairs Data</summary>
                            <div id="redundancyTable"></div>
                        </details>

                        <div class="interpretation">
                            <h4>Interpretation Guide:</h4>
                            <ul>
                                <li><strong>|r| &gt; 0.9:</strong> Very high redundancy - strongly consider dropping one feature</li>
                                <li><strong>|r| = 0.7-0.9:</strong> Moderate redundancy - features are related but may provide different information</li>
                                <li><strong>|r| = 0.5-0.7:</strong> Low redundancy - features are somewhat related</li>
                                <li><strong>|r| &lt; 0.5:</strong> Independent features - both should be kept</li>
                                <li><strong>Positive correlation:</strong> Features move together (e.g., "living" and "animacy")</li>
                                <li><strong>Negative correlation:</strong> Features move oppositely (e.g., "natural" and "artificial")</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="step-navigation">
                    <button id="step4Prev" class="btn-prev">← Previous</button>
                    <button id="step4Next" class="btn-next" disabled>Next: Item Similarity →</button>
                </div>
            </div>
        </section>

        <!-- Step 5: Item Similarity -->
        <section class="step-section" id="step5">
            <div class="card">
                <div class="step-header">
                    <h2>Step 5: Item Similarity</h2>
                </div>

                <div class="explanation">
                    <h3>What is Item Similarity?</h3>
                    <p>Item similarity identifies items (e.g., images) that have very similar feature profiles. Even with perfect features, if your items are too similar, brain prediction models will struggle to distinguish them.</p>

                    <details>
                        <summary>How does it work?</summary>
                        <div class="explanation-detail">
                            <p><strong>For each item (item_i):</strong></p>
                            <ol>
                                <li>Compute the average rating across raters separately for each feature</li>
                            </ol>
                            <p>Now for each of the 60 items, you have one rating (the avg rating) per feature.</p>
                            <p><strong>For each pair of items (item_i, item_j):</strong></p>
                            <ol>
                                <li>Correlate the feature ratings for (item_i, item_j) across features</li>                                
                            </ol>
                            <p><strong>High correlation = confusable items (your features don't distinguish between items)</strong></p>
                            <p>This could reveal a limitation of the stimulus set (items are too similar), or your features (need more fine-grained features).</p>
                        </div>
                    </details>

                    <div class="note">
                        <strong>Why does this matter?</strong>
                        <ul>
                            <li>High item similarity means "according to your features" the brain responses will be highly similar (this could be right!)</li>
                            <li>But, if in fact the brain distinguishes these items (at least in some regions) very high similarity scores could indicate you are missing key features.</li>
                            <li>Low scores (on at least some features) suggest your item set has good coverage</li>
                            <li>Goal: Diverse items with distinct feature profiles</li>
                        </ul>
                    </div>
                </div>

                <div id="similarityAnalysis">
                    <button id="computeSimilarityBtn" class="btn-primary">Compute Item Similarity</button>

                    <div id="similarityLoading" class="loading-message" style="display: none;">
                        <div class="spinner"></div>
                        <p>Computing item-vs-item correlations...</p>
                    </div>

                    <div id="similarityResults" style="display: none;">
                        <div class="results-header">
                            <h3>Item Similarity Results</h3>
                        </div>

                        <!-- Summary Statistics -->
                        <div id="similaritySummary" class="data-summary"></div>

                        <!-- Heatmap -->
                        <div class="heatmap-section">
                            <h4>Item-vs-Item Correlation Heatmap</h4>
                            <div class="results-header">
                                <p class="explanation-text">
                                    Shows correlation between each pair of items (averaged feature ratings across all raters).
                                    Darker red = items are very similar. Darker blue = items are very different.
                                </p>
                                <button id="downloadSimilarityHeatmap" class="btn-download">Download Heatmap (PNG)</button>
                            </div>
                            <div id="similarityHeatmap" class="plotly-heatmap"></div>
                        </div>

                        <!-- Threshold Control -->
                        <div class="threshold-control">
                            <label for="similarityThreshold">
                                Similarity Threshold: <span id="similarityThresholdValue">0.70</span>
                            </label>
                            <input
                                type="range"
                                id="similarityThreshold"
                                min="0"
                                max="1"
                                step="0.05"
                                value="0.7"
                            >
                            <p class="explanation-text">
                                Adjust the threshold to see which item pairs are above it.
                                Higher values (≥0.7) indicate confusable items that may limit prediction performance.
                            </p>
                        </div>

                        <!-- Bar Chart -->
                        <div class="chart-section">
                            <h4>Item Pairs Above Threshold</h4>
                            <div class="results-header">
                                <p class="explanation-text">
                                    Item pairs with correlation above the threshold, sorted from most to least similar.
                                </p>
                                <button id="downloadSimilarityChart" class="btn-download">Download Chart (PNG)</button>
                            </div>
                            <div class="chart-container">
                                <canvas id="similarityChart"></canvas>
                            </div>
                        </div>

                        <!-- Most Similar Pairs -->
                        <div class="chart-section">
                            <h4>Most Similar Item Pairs</h4>
                            <p class="explanation-text">
                                Item pairs sorted by correlation (highest first). These items have the most similar feature profiles.
                            </p>
                            <details class="data-table-section">
                                <summary>View Top 20 Most Similar Pairs</summary>
                                <div id="similarityTable"></div>
                            </details>
                        </div>

                        <div class="interpretation">
                            <h4>Interpretation Guide:</h4>
                            <ul>
                                <li><strong>r &gt; 0.8:</strong> Very similar items - nearly identical feature profiles</li>
                                <li><strong>r = 0.6-0.8:</strong> Moderately similar - some overlap in features</li>
                                <li><strong>r = 0.4-0.6:</strong> Somewhat similar - some shared properties</li>
                                <li><strong>r &lt; 0.4:</strong> Distinct items - good diversity</li>
                                <li><strong>High overall similarity:</strong> Indicates limited coverage of feature space</li>
                                <li><strong>Low overall similarity:</strong> Indicates good stimulus diversity</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="step-navigation">
                    <button id="step5Prev" class="btn-prev">← Previous</button>
                    <button id="step5Next" class="btn-next" disabled>Next: Decisions →</button>
                </div>
            </div>
        </section>

        <section class="step-section" id="step6">
            <div class="card">
                <h2>Step 6: Summary & Export</h2>

                <p class="explanation-text">
                    Review your analysis results and export the final cleaned dataset for your brain prediction models.
                </p>

                <button id="generateSummaryBtn" class="btn-primary">Generate Summary</button>
                <div id="summaryLoading" class="loading-indicator" style="display: none;">
                    <div class="spinner"></div>
                    <p>Generating summary...</p>
                </div>

                <div id="summaryResults" style="display: none; margin-top: 30px;">
                    <h3>Analysis Summary</h3>
                    <div id="summaryContent"></div>

                    <h3 style="margin-top: 30px;">Final Dataset</h3>
                    <div id="finalDatasetInfo"></div>

                    <div style="margin-top: 20px;">
                        <button id="downloadFinalDataBtn" class="btn-primary">Download Final Dataset (CSV)</button>
                        <button id="copySummaryBtn" class="btn-secondary" style="margin-left: 10px;">Copy Summary to Clipboard</button>
                    </div>

                    <h3 style="margin-top: 30px;">Recommendations</h3>
                    <div id="recommendationsContent"></div>
                </div>

                <div class="step-navigation" style="margin-top: 30px;">
                    <button id="step6Prev" class="btn-prev">← Previous</button>
                </div>
            </div>
        </section>
    </div>

    <!-- External Libraries -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.4.1/papaparse.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
    <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>

    <!-- Custom Libraries -->
    <script src="lib/dataframe.js"></script>
    <script src="lib/stats.js"></script>

    <!-- Main Script -->
    <script src="script.js"></script>
</body>
</html>
