"""
Feature data loading and preparation functions

Handles loading feature ratings from S3 and preparing them for analysis
"""

import numpy as np
import boto3
import pandas as pd
import io


s3_client = boto3.client('s3', region_name='us-east-1')
BUCKET_NAME = 'neuroscience-fiction'


# Mitchell's canonical item order (grouped by category)
MITCHELL_ITEM_ORDER = [
    'bear', 'cat', 'cow', 'dog', 'horse',  # animals
    'arm', 'eye', 'foot', 'hand', 'leg',  # body parts
    'apartment', 'barn', 'church', 'house', 'igloo',  # buildings
    'arch', 'chimney', 'closet', 'door', 'window',  # building parts
    'coat', 'dress', 'pants', 'shirt', 'skirt',  # clothing
    'bed', 'chair', 'desk', 'dresser', 'table',  # furniture
    'ant', 'bee', 'beetle', 'butterfly', 'fly',  # insects
    'bottle', 'cup', 'glass', 'knife', 'spoon',  # kitchen utensils
    'bell', 'key', 'refrigerator', 'telephone', 'watch',  # man-made objects
    'chisel', 'hammer', 'pliers', 'saw', 'screwdriver',  # tools
    'carrot', 'celery', 'corn', 'lettuce', 'tomato',  # vegetables
    'airplane', 'bicycle', 'car', 'train', 'truck'  # vehicles
]


def load_feature_data_from_s3(year, group_name):
    """
    Load feature ratings from S3 (via csv-generator Lambda)

    Args:
        year: str - Year (e.g., '2025')
        group_name: str - Group name (e.g., 'Testing')

    Returns:
        dict with:
            - R: [numItems, numFeatures] array of average ratings
            - itemNames: [numItems] array of item names
            - featureNames: [numFeatures] array of feature names
    """
    # Get CSV from S3 (generated by csv-generator Lambda)
    s3_key = f'survey/{year}/{group_name}/featureRatings_{group_name}{year}.csv'

    print(f'Loading feature data from s3://{BUCKET_NAME}/{s3_key}')

    try:
        response = s3_client.get_object(Bucket=BUCKET_NAME, Key=s3_key)
        csv_content = response['Body'].read()
        df = pd.read_csv(io.BytesIO(csv_content))
    except s3_client.exceptions.NoSuchKey:
        raise FileNotFoundError(
            f'Feature ratings not found at s3://{BUCKET_NAME}/{s3_key}. '
            f'Make sure you\'ve generated ratings for {group_name} {year}.'
        )

    # Get unique values
    itemNames = sorted(df.itemName.unique())
    featureNames = sorted(df.featureName.unique())
    raters = sorted(df.workerId.unique())

    numItems = len(itemNames)
    numFeatures = len(featureNames)
    numRaters = len(raters)

    print(f'Found {numItems} items, {numFeatures} features, {numRaters} raters')

    # Validate we have all 60 Mitchell items
    if numItems != 60:
        raise ValueError(f'Expected 60 items, got {numItems}')

    # Initialize ratings matrix
    R = np.zeros((numItems, numFeatures))

    # Reorder items to match Mitchell's canonical order
    itemNames = MITCHELL_ITEM_ORDER.copy()

    # Fill in average ratings for each item/feature combination
    for itemNum, itemName in enumerate(itemNames):
        for featureNum, featureName in enumerate(featureNames):
            subset = df[(df.itemName == itemName) & (df.featureName == featureName)]
            numRatings = len(subset)
            assert numRatings == numRaters, \
                f'Expected {numRaters} ratings for {itemName}/{featureName}, got {numRatings}'
            # Use ratingScaled (0-1 scale) as in notebook
            R[itemNum, featureNum] = subset.ratingsScaled.mean()

    feature_data = {
        'R': R,
        'itemNames': np.asarray(itemNames, dtype='object'),
        'featureNames': np.asarray(featureNames, dtype='object')
    }

    return feature_data


def prepare_ratings(feature_data, shuffle=False):
    """
    Prepare feature ratings for analysis

    Args:
        feature_data: dict from load_feature_data_from_s3()
        shuffle: bool - Shuffle features (for sanity check)

    Returns:
        R: [numItems, numFeatures] array of ratings
    """
    # Ensure correct orientation
    if feature_data['R'].shape[1] == 60:
        R = np.transpose(feature_data['R'])
    else:
        R = feature_data['R']

    # Shuffle for sanity check (should destroy prediction)
    if shuffle:
        R = np.array([r[np.random.permutation(r.shape[0])] for r in R])

    return R
